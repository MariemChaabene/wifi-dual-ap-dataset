{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db147601-7251-49e8-84ef-40f23ed74dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fusion réalisée : 7 lignes appariées (tolérance 5s)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# --------------------------------------------\n",
    "# Paramètres\n",
    "# --------------------------------------------\n",
    "TOLERANCE_SECONDS = 5  # tolérance de fusion temporelle\n",
    "wifi_ap1_file = \"wifi_log2_ap1.jsonl\"\n",
    "wifi_ap2_file = \"wifi_log2_ap2.jsonl\"\n",
    "server_ap1_file = \"trafic_metrics_server1.jsonl\"\n",
    "server_ap2_file = \"trafic_metrics_server2.jsonl\"\n",
    "\n",
    "# --------------------------------------------\n",
    "# Fonction de préparation d'un AP\n",
    "# --------------------------------------------\n",
    "def prepare_ap(wifi_file, server_file, suffix):\n",
    "    # Charger Wi-Fi (jsonl)\n",
    "    df_wifi = pd.read_json(wifi_file, lines=True)\n",
    "\n",
    "    # Supprimer les lignes sans throughput (pas de test en cours)\n",
    "    if \"throughput_bps\" in df_wifi.columns:\n",
    "        df_wifi = df_wifi[df_wifi[\"throughput_bps\"].notnull()].copy()\n",
    "\n",
    "    # Aplatir la liste \"clients\"\n",
    "    if \"clients\" in df_wifi.columns:\n",
    "        df_exp = df_wifi.explode(\"clients\")\n",
    "        clients = pd.json_normalize(df_exp[\"clients\"])\n",
    "    else:\n",
    "        df_exp = df_wifi.copy()\n",
    "        clients = pd.DataFrame()\n",
    "\n",
    "    # Colonnes globales\n",
    "    global_cols = [c for c in df_exp.columns if c != \"clients\"]\n",
    "    global_data = df_exp[global_cols].reset_index(drop=True)\n",
    "    clients = clients.reset_index(drop=True)\n",
    "\n",
    "    df_flat = pd.concat([global_data, clients], axis=1)\n",
    "\n",
    "    # Charger serveur (trafic reçu)\n",
    "    df_server = pd.read_json(server_file, lines=True)\n",
    "\n",
    "    # Fusion via traffic_label\n",
    "    if \"traffic_label\" in df_flat.columns and \"traffic_label\" in df_server.columns:\n",
    "        df_flat = pd.merge(\n",
    "            df_flat,\n",
    "            df_server,\n",
    "            on=\"traffic_label\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_server\")\n",
    "        )\n",
    "\n",
    "    # Convertir timestamps\n",
    "    # côté Wi-Fi : \"timestamp\" ; côté serveur : \"timestamp_server\" éventuellement\n",
    "    if \"timestamp\" in df_flat.columns:\n",
    "        df_flat[\"timestamp\"] = pd.to_datetime(df_flat[\"timestamp\"], errors=\"coerce\")\n",
    "    if \"timestamp_server\" in df_flat.columns:\n",
    "        df_flat[\"timestamp_server\"] = pd.to_datetime(df_flat[\"timestamp_server\"], errors=\"coerce\")\n",
    "\n",
    "    # Ajouter suffixe aux colonnes (sauf colonne de fusion temporelle)\n",
    "    # On garde une colonne 'timestamp_<suffix>' pour clarté\n",
    "    df_flat = df_flat.rename(columns={\"timestamp\": f\"timestamp_{suffix}\"})\n",
    "    # Ajouter suffixe à toutes les autres colonnes sauf traffic_label (qu’on garde pour référence)\n",
    "    cols_to_rename = {\n",
    "        c: f\"{c}_{suffix}\"\n",
    "        for c in df_flat.columns\n",
    "        if c not in [f\"timestamp_{suffix}\", \"traffic_label\"]\n",
    "    }\n",
    "    df_flat = df_flat.rename(columns=cols_to_rename)\n",
    "\n",
    "    return df_flat\n",
    "\n",
    "# --------------------------------------------\n",
    "# Préparer AP1 et AP2\n",
    "# --------------------------------------------\n",
    "ap1 = prepare_ap(wifi_ap1_file, server_ap1_file, \"ap1\")\n",
    "ap2 = prepare_ap(wifi_ap2_file, server_ap2_file, \"ap2\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Fusion temporelle horizontale\n",
    "# --------------------------------------------\n",
    "# On utilise merge_asof avec tolérance\n",
    "# Il faut trier par timestamp\n",
    "ap1_sorted = ap1.sort_values(by=\"timestamp_ap1\").reset_index(drop=True)\n",
    "ap2_sorted = ap2.sort_values(by=\"timestamp_ap2\").reset_index(drop=True)\n",
    "\n",
    "# merge_asof fusionne en appariant chaque ligne AP1 avec la plus proche AP2\n",
    "merged = pd.merge_asof(\n",
    "    ap1_sorted,\n",
    "    ap2_sorted,\n",
    "    left_on=\"timestamp_ap1\",\n",
    "    right_on=\"timestamp_ap2\",\n",
    "    direction=\"nearest\",\n",
    "    tolerance=pd.Timedelta(seconds=TOLERANCE_SECONDS)\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Option : filtrer les lignes sans correspondance (si désiré)\n",
    "# (les lignes où aucune correspondance AP2 dans la tolérance auront NaN)\n",
    "merged_valid = merged.dropna(subset=[\"timestamp_ap2\"]).copy()\n",
    "\n",
    "# --------------------------------------------\n",
    "# Sauvegarde\n",
    "# --------------------------------------------\n",
    "merged_valid.to_csv(\"dual_ap_horizontal_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Fusion réalisée : {len(merged_valid)} lignes appariées (tolérance {TOLERANCE_SECONDS}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99e4c7-cf58-4460-934d-2bf50b73e9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
